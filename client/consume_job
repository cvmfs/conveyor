#!/usr/bin/env python3

import argparse
import json
import os
import pika
import subprocess
import time

from common import CvmfsTransaction, read_config
from pathlib import Path
from urllib.parse import urlparse
from urllib.request import urlretrieve

# Constant values
job_exchange = 'jobs.new'
job_queue = 'jobs.new'
job_routing_key = ''

# Global values (should be constant during run time)
temp_dir = '/tmp'

def parse_args():
    parser = argparse.ArgumentParser(description='Process some integers.')
    parser.add_argument(
        '-c', '--config', default='/etc/cvmfs/publisher/config.json', help='config file')
    parser.add_argument(
        '--temp-dir', default='/tmp', help='temporary dir for use during CVMFS transaction'
    )
    return parser.parse_args()


def callback(ch, method, properties, body):
    job = json.loads(body)
    print('-- Start publishing job {}'.format(job['id']))

    try:
        run_cvmfs_transaction(job)
        ch.basic_ack(delivery_tag=method.delivery_tag)
    except Exception as e:
        print('Exception raised during CVMFS transaction: {}'.format(e))
        # TODO: change the following to a resubmit with retry += 1
        ch.basic_nack(delivery_tag=method.delivery_tag,
                      multiple=False, requeue=True)

    print('-- Finished publishing job {}'.format(job['id']))


def run_cvmfs_transaction(job):
    with CvmfsTransaction(job):
        # save payload into temp dir
        url = urlparse(job['payload'])
        payload_file_name = temp_dir + '/' + Path(url.path).name
        payload_file_name, _ = urlretrieve(job['payload'], filename=payload_file_name)

        # untar payload into path dir
        target_dir = '/cvmfs/' + job['repo'] + '/' + job['path']
        subprocess.run(['tar', '-C', target_dir, '-xf', payload_file_name], check=True)

        # (optional) unpack transaction script into tmp dir
        # run transaction script

    # cleanup payload temp file
    os.remove(payload_file_name)


def main():
    arguments = parse_args()

    global temp_dir
    temp_dir = arguments.temp_dir

    config_file = arguments.config

    config = read_config(config_file)
    rmq_config = config['rabbitmq']

    credentials = pika.PlainCredentials(rmq_config['username'],
                                        rmq_config['password'])
    parameters = pika.ConnectionParameters(rmq_config['url'],
                                           rmq_config['port'],
                                           rmq_config['vhost'],
                                           credentials)
    connection = pika.BlockingConnection(parameters)
    channel = connection.channel()
    channel.basic_qos(prefetch_count=1)

    result = channel.queue_declare(queue=job_queue)
    queue = result.method.queue
    channel.queue_bind(exchange=job_exchange, routing_key='', queue=queue)
    channel.basic_consume(callback,
                          queue=queue,
                          no_ack=False)

    print('-- Waiting for jobs. To exit, press Ctrl-C')
    channel.start_consuming()


if __name__ == '__main__':
    main()
